{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "usual-loading",
   "metadata": {},
   "source": [
    "4-4. 실습 (1) 데이터 다듬기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "asian-giant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First Citizen:', 'Before we proceed any further, hear me speak.', '', 'All:', 'Speak, speak.', '', 'First Citizen:', 'You are all resolved rather to die than to famish?', '']\n"
     ]
    }
   ],
   "source": [
    "import os, re \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 파일을 읽기모드로 열고\n",
    "# 라인 단위로 끊어서 list 형태로 읽어옵니다.\n",
    "file_path = os.getenv('HOME') + '/aiffel/lyricist/data/shakespeare.txt'\n",
    "with open(file_path, \"r\") as f:\n",
    "    raw_corpus = f.read().splitlines()\n",
    "\n",
    "# 앞에서부터 10라인만 화면에 출력해 볼까요?\n",
    "print(raw_corpus[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "driving-vertex",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before we proceed any further, hear me speak.\n",
      "Speak, speak.\n",
      "You are all resolved rather to die than to famish?\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
    "\n",
    "    if idx > 9: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-transition",
   "metadata": {},
   "source": [
    "텍스트 분류 모델에서 많이 보신 것처럼 텍스트 생성 모델에도 단어 사전을 만들게 됩니다. 그렇다면 문장을 일정한 기준으로 쪼개야겠죠? 그 과정을 토큰화(Tokenize) 라고 합니다.\n",
    "\n",
    "가장 심플한 방법은 띄어쓰기를 기준으로 나누는 방법이고, 우리도 그 방법을 사용할 겁니다. 하지만 약간의 문제가 있을 수 있죠. 몇 가지 문제 케이스를 살펴보죠.\n",
    "\n",
    "Hi, my name is John. *(\"Hi,\" \"my\", ..., \"john.\" 으로 분리됨) - 문장부호\n",
    "First, open the first chapter. *(First와 first를 다른 단어로 인식) - 대소문자\n",
    "He is a ten-year-old boy. *(ten-year-old를 한 단어로 인식) - 특수문자\n",
    "\"1.\" 을 막기 위해 문장 부호 양쪽에 공백을 추가 할 거고요, \"2.\" 를 막기 위해 모든 문자들을 소문자로 변환 할 겁니다. \"3.\"을 막기 위해 특수문자들은 모두 제거 하도록 하죠!\n",
    "\n",
    "이런 전처리를 위해 정규표현식(Regex)을 이용한 필터링이 유용하게 사용됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chief-compact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "#     2. 특수문자 양쪽에 공백을 넣고\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "#     5. 다시 양쪽 공백을 지웁니다\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-marking",
   "metadata": {},
   "source": [
    "자연어처리 분야에서 모델의 입력이 되는 문장을 소스 문장(Source Sentence) , 정답 역할을 하게 될 모델의 출력 문장을 타겟 문장(Target Sentence) 라고 관례적으로 부릅니다. 각각 X_train, y_train 에 해당한다고 할 수 있겠죠?\n",
    "\n",
    "그렇다면 우리는 위에서 만든 정제 함수를 통해 만든 데이터셋에서 토큰화를 진행한 후 끝 단어 <end>를 없애면 소스 문장, 첫 단어 <start>를 없애면 타겟 문장이 되겠죠? 이 정제 함수를 활용해서 아래와 같이 정제 데이터를 구축합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "closing-decline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> before we proceed any further , hear me speak . <end>',\n",
       " '<start> speak , speak . <end>',\n",
       " '<start> you are all resolved rather to die than to famish ? <end>',\n",
       " '<start> resolved . resolved . <end>',\n",
       " '<start> first , you know caius marcius is chief enemy to the people . <end>',\n",
       " '<start> we know t , we know t . <end>',\n",
       " '<start> let us kill him , and we ll have corn at our own price . <end>',\n",
       " '<start> is t a verdict ? <end>',\n",
       " '<start> no more talking on t let it be done away , away ! <end>',\n",
       " '<start> one word , good citizens . <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모을겁니다\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과를 10개만 확인해보죠\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-department",
   "metadata": {},
   "source": [
    "이제 데이터는 완벽하게 준비가 된 것 같네요!\n",
    "\n",
    "자, 새로운 언어를 배우는 상상을 해봅시다. 영어를 전혀 모르던 그 때로 돌아가서, 다시 영어를 배우려면 어떻게 해야 할까요? 영한사전 을 허리춤에 끼고 문장 속 단어를 하나하나 찾아가며 한국어 해석 을 적겠죠? 이 아이디어는 인공지능에게도 똑같이 적용됩니다. 배우고자 하는 언어 를 모국어로 표현 을 해야 공부를 할 수 있어요.\n",
    "\n",
    "인공지능의 모국어라면 단연 숫자 겠죠. 우리는 가르칠 언어(데이터)를 숫자로 변환해서 인공지능에게 줄 겁니다. 이에 필요한 것은 사전 ! 굳이 명명하자면... 데숫사전...?\n",
    "\n",
    "텐서플로우는 자연어 처리를 위한 여러 가지 모듈을 제공하는데, 우리도 그 모듈을 십분 활용할 겁니다! 아래에서 활용하게 될 tf.keras.preprocessing.text.Tokenizer 패키지는 정제된 데이터를 토큰화하고, 단어 사전(vocabulary 또는 dictionary라고 칭함)을 만들어주며, 데이터를 숫자로 변환까지 한 방에 해줍니다. 이 과정을 벡터화(vectorize) 라 하며, 숫자로 변환된 데이터를 텐서(tensor) 라고 칭합니다. 우리가 사용하는 텐서플로우로 만든 모델의 입출력 데이터는 실제로는 모두 이런 텐서로 변환되어 처리되는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "posted-horror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  143   40 ...    0    0    0]\n",
      " [   2  110    4 ...    0    0    0]\n",
      " [   2   11   50 ...    0    0    0]\n",
      " ...\n",
      " [   2  149 4553 ...    0    0    0]\n",
      " [   2   34   71 ...    0    0    0]\n",
      " [   2  945   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f04f9629390>\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n",
    "# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    "def tokenize(corpus):\n",
    "    # 7000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
    "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
    "    # 7000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=7000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "noticed-barrel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  143   40  933  140  591    4  124   24  110]\n",
      " [   2  110    4  110    5    3    0    0    0    0]\n",
      " [   2   11   50   43 1201  316    9  201   74    9]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :10]) # 생성된 텐서 데이터를 3번째 행, 10번째 열까지만 출력해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-twenty",
   "metadata": {},
   "source": [
    "텐서 데이터는 모두 정수로 이루어져 있습니다. 이 숫자는 다름 아니라, tokenizer에 구축된 단어 사전의 인덱스입니다. 단어 사전이 어떻게 구축되었는지 아래와 같이 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "frozen-safety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : .\n",
      "6 : the\n",
      "7 : and\n",
      "8 : i\n",
      "9 : to\n",
      "10 : of\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break # 인덱스가 10 이상이면 break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-peter",
   "metadata": {},
   "source": [
    "어떻습니까? 2번 인덱스가 바로 <start>였습니다. 왜 모든 행이 2로 시작하는지 이해할 수 있겠습니다.\n",
    "\n",
    "이제 생성된 텐서를 소스와 타겟으로 분리하여 모델이 학습할 수 있게 하겠습니다. 이 과정도 텐서플로우 가 제공하는 모듈을 사용할 것이니, 어떻게 사용하는지만 눈여겨 봐둡시다.\n",
    "\n",
    "텐서 출력부에서 행 뒤쪽에 0이 많이 나온 부분은 정해진 입력 시퀀스 길이보다 문장이 짧을 경우 0으로 패딩(padding)을 채워 넣은 것입니다. 사전에는 없지만 0은 바로 패딩 문자 <pad>가 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "individual-georgia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0\n",
      "   0   0]\n",
      "[143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0   0\n",
      "   0   0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-spectacular",
   "metadata": {},
   "source": [
    "corpus 내의 첫 번째 문장에 대해 생성된 소스와 타겟 문장을 확인해 보았습니다. 예상대로 소스는 2(<start>)에서 시작해서 3(<end>)으로 끝난 후 0(<pad>)로 채워져 있습니다. 하지만 타겟은 2로 시작하지 않고 소스를 왼쪽으로 한 칸 시프트 한 형태를 가지고 있습니다.\n",
    "\n",
    "마지막으로 우리는 데이터셋 객체를 생성할 것입니다. 그동안 우리는 model.fit(x_train, y_train, ...) 형태로 Numpy Array 데이터셋을 생성하여 model에 제공하는 형태의 학습을 많이 진행해 왔습니다. 그러나 텐서플로우를 활용할 경우 텐서로 생성된 데이터를 이용해 tf.data.Dataset객체를 생성하는 방법을 흔히 사용합니다. tf.data.Dataset객체는 텐서플로우에서 사용할 경우 데이터 입력 파이프라인을 통한 속도 개선 및 각종 편의 기능을 제공하므로 꼭 사용법을 알아 두시기를 권합니다. 우리는 이미 데이터셋을 텐서 형태로 생성해 두었으므로, tf.data.Dataset.from_tensor_slices() 메소드를 이용해 tf.data.Dataset객체를 생성할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "generic-admission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 20), (256, 20)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
    "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
    "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-algeria",
   "metadata": {},
   "source": [
    "이번 스텝에서 데이터셋을 생성하기 위해 거쳐 온 과정을 잘 기억해 두시길 바랍니다.\n",
    "\n",
    "- 정규표현식을 이용한 corpus 생성\n",
    "- tf.keras.preprocessing.text.Tokenizer를 이용해 corpus를 텐서로 변환\n",
    "- tf.data.Dataset.from_tensor_slices()를 이용해 corpus 텐서를 tf.data.Dataset객체로 변환\n",
    "\n",
    "dataset을 얻음으로써 데이터 다듬기 과정은 끝났습니다. tf.data.Dataset에서 제공하는 shuffle(), batch() 등 다양한 데이터셋 관련 기능을 손쉽게 이용할 수 있게 되었군요.\n",
    "\n",
    "이 모든 일련의 과정을 텐서플로우에서의 데이터 전처리 라 칭합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-worker",
   "metadata": {},
   "source": [
    "4-5. 실습 (2) 인공지능 학습시키기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "educational-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-discount",
   "metadata": {},
   "source": [
    "텍스트 분류 모델을 다루어 보셨다면 Embedding 레이어의 역할에 대해서는 낯설지 않을 것입니다. 우리 입력 텐서에는 단어 사전의 인덱스가 들어 있습니다. Embedding 레이어는 이 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔 줍니다. 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현(representation)으로 사용됩니다.\n",
    "\n",
    "위 코드에서 embedding_size 는 워드 벡터의 차원수, 즉 단어가 추상적으로 표현되는 크기입니다. 만약 그 크기가 2라면 예를 들어\n",
    "\n",
    "- 차갑다: [0.0, 1.0]\n",
    "- 뜨겁다: [1.0, 0.0]\n",
    "- 미지근하다: [0.5, 0.5]\n",
    "\n",
    "정도의 구분이 가능하겠군요. 값이 커질수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만, 그만큼 충분한 데이터가 주어지지 않으면 오히려 혼란만을 야기할 수 있습니다. 이번 실습에서는 256이 적당해 보이네요.\n",
    "\n",
    "LSTM 레이어의 hidden state 의 차원수인 hidden_size 도 같은 맥락입니다. hidden_size 는 모델에 얼마나 많은 일꾼을 둘 것인가? 로 이해해도 크게 엇나가지 않습니다. 그 일꾼들은 모두 같은 데이터를 보고 각자의 생각을 가지는데, 역시 충분한 데이터가 주어지면 올바른 결정을 내리겠지만 그렇지 않으면 배가 산으로 갈 뿐 입니다. 이번 실습에는 1024가 적당해보이는군요.\n",
    "\n",
    "우리의 model은 아직 제대로 build되지 않았습니다. model.compile()을 호출한 적도 없고, 아직 model의 입력 텐서가 무엇인지 제대로 지정해 주지도 않았기 때문입니다.\n",
    "그런 경우 아래와 같이 model에 데이터를 아주 조금 태워 보는 것도 방법입니다. model의 input shape가 결정되면서 model.build()가 자동으로 호출됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prepared-apparel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 20, 7001), dtype=float32, numpy=\n",
       "array([[[ 5.10321224e-05, -1.21536315e-04,  1.86351259e-04, ...,\n",
       "          2.54257111e-06,  2.56849424e-04,  8.17465916e-05],\n",
       "        [-1.52505585e-04,  1.36655770e-04,  3.52020434e-04, ...,\n",
       "         -2.23279421e-04,  6.16769306e-04,  2.22252274e-04],\n",
       "        [-8.72967430e-05,  3.35696619e-04,  4.74986766e-04, ...,\n",
       "         -5.45724724e-05,  6.84756786e-04,  1.78641436e-04],\n",
       "        ...,\n",
       "        [-1.42985873e-03,  1.33758225e-03,  1.40110380e-03, ...,\n",
       "          3.52989184e-04,  2.69040640e-04,  1.06144114e-03],\n",
       "        [-1.50609459e-03,  1.76364090e-03,  2.10960023e-03, ...,\n",
       "          2.68676988e-04,  2.15465523e-04,  1.60291081e-03],\n",
       "        [-1.59191224e-03,  2.15453026e-03,  2.75303214e-03, ...,\n",
       "          1.63100616e-04,  1.66759826e-04,  2.17933673e-03]],\n",
       "\n",
       "       [[ 5.10321224e-05, -1.21536315e-04,  1.86351259e-04, ...,\n",
       "          2.54257111e-06,  2.56849424e-04,  8.17465916e-05],\n",
       "        [-3.53112729e-04,  1.55648682e-04,  4.38572606e-04, ...,\n",
       "         -2.28087301e-04,  5.24818315e-04,  2.40224603e-04],\n",
       "        [-3.15420475e-04,  2.50823196e-05,  2.51258112e-04, ...,\n",
       "         -2.86937895e-04,  1.08228892e-03,  3.15914309e-04],\n",
       "        ...,\n",
       "        [-1.81485596e-03,  3.09099047e-03,  5.18323993e-03, ...,\n",
       "         -3.99951765e-04, -1.91613406e-04,  4.76422114e-03],\n",
       "        [-1.99648598e-03,  3.18180467e-03,  5.34095708e-03, ...,\n",
       "         -4.58006660e-04, -1.91174317e-04,  5.10567892e-03],\n",
       "        [-2.16811779e-03,  3.24319885e-03,  5.46461949e-03, ...,\n",
       "         -5.11433580e-04, -1.86295641e-04,  5.39840339e-03]],\n",
       "\n",
       "       [[ 5.10321224e-05, -1.21536315e-04,  1.86351259e-04, ...,\n",
       "          2.54257111e-06,  2.56849424e-04,  8.17465916e-05],\n",
       "        [ 1.63753793e-04,  1.76102738e-04, -2.80576816e-04, ...,\n",
       "         -2.02325518e-05,  6.86734507e-04,  2.01870178e-04],\n",
       "        [ 3.10831791e-04,  3.26048932e-04, -2.12513143e-04, ...,\n",
       "         -4.04212857e-04,  1.00532756e-03,  3.12295335e-04],\n",
       "        ...,\n",
       "        [-2.41319160e-03,  3.29640135e-03,  5.74505655e-03, ...,\n",
       "         -5.05524862e-04, -3.25159141e-04,  5.34178969e-03],\n",
       "        [-2.54937983e-03,  3.33205424e-03,  5.81009220e-03, ...,\n",
       "         -5.67253272e-04, -2.92173267e-04,  5.63098630e-03],\n",
       "        [-2.67456658e-03,  3.34864832e-03,  5.85768931e-03, ...,\n",
       "         -6.22714870e-04, -2.62221467e-04,  5.87153248e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 5.10321224e-05, -1.21536315e-04,  1.86351259e-04, ...,\n",
       "          2.54257111e-06,  2.56849424e-04,  8.17465916e-05],\n",
       "        [-1.77655544e-04, -3.51058989e-04,  2.20417278e-05, ...,\n",
       "         -2.29236000e-04,  7.37782277e-04,  2.02973606e-04],\n",
       "        [-3.47889814e-04, -1.31098626e-04, -3.69446294e-04, ...,\n",
       "         -5.82063221e-04,  1.15767913e-03, -2.62138883e-06],\n",
       "        ...,\n",
       "        [-1.20329123e-03,  2.55263993e-03,  3.24934139e-03, ...,\n",
       "          2.17327703e-04, -7.03953148e-04,  2.10161018e-03],\n",
       "        [-1.33932952e-03,  2.77860346e-03,  3.78740556e-03, ...,\n",
       "          1.41383207e-04, -7.04190345e-04,  2.67143524e-03],\n",
       "        [-1.48780411e-03,  2.97035766e-03,  4.23355354e-03, ...,\n",
       "          5.62150890e-05, -6.84526400e-04,  3.22537730e-03]],\n",
       "\n",
       "       [[ 5.10321224e-05, -1.21536315e-04,  1.86351259e-04, ...,\n",
       "          2.54257111e-06,  2.56849424e-04,  8.17465916e-05],\n",
       "        [ 1.47515631e-04, -4.67267615e-04,  3.44442815e-04, ...,\n",
       "          5.08372796e-05,  3.66578432e-04,  6.50132642e-05],\n",
       "        [ 2.19472684e-04, -1.07420943e-04,  2.07214354e-04, ...,\n",
       "         -2.34197360e-04,  3.55117169e-04, -2.93335586e-04],\n",
       "        ...,\n",
       "        [-7.87347555e-04,  1.68918725e-03,  2.18245434e-03, ...,\n",
       "          4.38970950e-04, -4.92084539e-04,  1.87134414e-04],\n",
       "        [-9.58617544e-04,  1.96881266e-03,  2.84022419e-03, ...,\n",
       "          2.79320171e-04, -4.55011148e-04,  8.62563669e-04],\n",
       "        [-1.12931803e-03,  2.24293419e-03,  3.40839359e-03, ...,\n",
       "          1.20603341e-04, -4.21058707e-04,  1.57138554e-03]],\n",
       "\n",
       "       [[ 5.10321224e-05, -1.21536315e-04,  1.86351259e-04, ...,\n",
       "          2.54257111e-06,  2.56849424e-04,  8.17465916e-05],\n",
       "        [ 2.54341809e-04, -1.48446692e-04,  2.10106795e-04, ...,\n",
       "          8.62640154e-05,  5.74889302e-04, -8.71786615e-05],\n",
       "        [ 4.76129208e-04,  2.66299670e-04,  1.94854452e-04, ...,\n",
       "         -2.32879347e-06,  4.92860272e-04, -2.16721368e-04],\n",
       "        ...,\n",
       "        [-1.47326954e-03,  1.32682000e-03,  4.64823376e-03, ...,\n",
       "         -3.23745713e-04, -1.30341796e-03,  2.12140760e-04],\n",
       "        [-1.59348326e-03,  1.70083682e-03,  5.01474179e-03, ...,\n",
       "         -4.05581086e-04, -1.15571439e-03,  1.02037436e-03],\n",
       "        [-1.71936047e-03,  2.04854948e-03,  5.30699221e-03, ...,\n",
       "         -4.85629949e-04, -1.01405627e-03,  1.80447183e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
    "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-intelligence",
   "metadata": {},
   "source": [
    "모델의 최종 출력 텐서 shape를 유심히 보면 shape=(256, 20, 7001)임을 알 수 있습니다. 7001은 Dense 레이어의 출력 차원수입니다. 7001개의 단어 중 어느 단어의 확률이 가장 높을지를 모델링해야 하기 때문입니다.\n",
    "256은 이전 스텝에서 지정한 배치 사이즈입니다. dataset.take(1)를 통해서 1개의 배치, 즉 256개의 문장 데이터를 가져온 것입니다.\n",
    "\n",
    "그렇다면 20은 무엇을 의미할까요? 비밀은 바로 tf.keras.layers.LSTM(hidden_size, return_sequences=True)로 호출한 LSTM 레이어에서 return_sequences=True이라고 지정한 부분에 있습니다. 즉, LSTM은 자신에게 입력된 시퀀스의 길이만큼 동일한 길이의 시퀀스를 출력한다는 의미입니다. 만약 return_sequences=False였다면 LSTM 레이어는 1개의 벡터만 출력했을 것입니다.\n",
    "\n",
    "그런데 문제는, 우리의 모델은 입력 데이터의 시퀀스 길이가 얼마인지 모른다는 점입니다. 모델을 만들면서 알려준 적도 없습니다. 그럼 20은 언제 알게된 것일까요? 네, 그렇습니다. 데이터를 입력받으면서 비로소 알게 된 것입니다. 우리 데이터셋의 max_len이 20으로 맞춰져 있었던 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "qualified-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  1792256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  7176025   \n",
      "=================================================================\n",
      "Total params: 22,607,961\n",
      "Trainable params: 22,607,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-period",
   "metadata": {},
   "source": [
    "이제 드디어 model.summary()를 호출할 수 있게 되었습니다. 그런데 호출해 보니 그동안 많이 보았던 것과는 다른 점이 있습니다. 우리가 궁금했던 Output Shape를 정확하게 알려주지 않습니다. 바로 위에서 설명한 이유 때문입니다. 우리의 모델은 입력 시퀀스의 길이를 모르기 때문에 Output Shape를 특정할 수 없는 것입니다.\n",
    "\n",
    "하지만 모델의 파라미터 사이즈는 측정됩니다. 대략 22million 정도 되는군요. 참고로 서두에 소개했던 GPT-2의 파라미터 사이즈는, 1.5billion입니다. 우리 모델의 100배까지는 안되더라도 수십배가 넘는군요. 놀라지 마세요. GPT-3의 파라미터 사이즈는 GPT-2의 100배니까요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-interview",
   "metadata": {},
   "source": [
    "학습엔 15분 정도 소요됩니다(GPU 환경 기준). 간단한 스트레칭과 커피 한 잔을 만들어 오기에 적당한 시간이죠.\n",
    "혹시라도 학습에 지나치게 많은 시간이 소요된다면 tf.test.is_gpu_available() 소스를 실행해 텐서플로우가 GPU를 잘 사용하고 있는지 확인하시길 바랍니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tropical-ownership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "62/93 [===================>..........] - ETA: 11s - loss: 4.8105"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-53bb5dbd7ade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer와 loss등은 차차 배웁니다\n",
    "# 혹시 미리 알고 싶다면 아래 문서를 참고하세요\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "# 양이 상당히 많은 편이니 지금 보는 것은 추천하지 않습니다\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-jones",
   "metadata": {},
   "source": [
    "Loss는 모델이 오답을 만들고 있는 정도라고 생각하셔도 좋습니다(그렇다고 Loss가 1일 때 99%를 맞추고 있다는 의미는 아닙니다). 오답률이 감소하고 있으니 학습이 잘 진행되고 있다 고 해석할 수 있죠!\n",
    "\n",
    "학습이 완료되었다면 이제 모델을 평가해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-handy",
   "metadata": {},
   "source": [
    "# 4-6. 실습 (3) 잘 만들어졌는지 평가하기\n",
    "\n",
    "모델이 작문을 잘하는지 컴퓨터 알고리즘이 평가하는 것은 무리가 있습니다. 만약에 그게 가능했다면 우리가 지금껏 해온 독후감 숙제를 컴퓨터가 채점했겠죠? 따라서 작문 모델을 평가하는 가장 확실한 방법은 작문을 시켜보고 직접 평가하는 겁니다. 아래 generate_text 함수는 모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행하게 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-cycling",
   "metadata": {},
   "source": [
    "텍스트를 생성하는 함수 안을 들여다보면 while문이 하나 자리 잡고 있는 것을 볼 수 있습니다. 왜 그럴까요?\n",
    "\n",
    "학습 단계에서 우리는 이런 while 문이 필요 없었습니다. 소스 문장과 타겟 문장이 있었고, 우리는 소스 문장을 모델에 입력해서 나온 결과를 타겟 문장과 직접 비교하면 그만이었습니다.\n",
    "그러나 텍스트를 실제로 생성해야 하는 시점에서, 우리에게는 2가지가 없습니다. 하나는 타겟 문장입니다. 또 하나는 무엇이냐 하면, 소스 문장입니다. 생각해 보면 우리는 텍스트 생성 태스크를 위해 테스트 데이터셋을 따로 생성한 적이 없습니다.\n",
    "\n",
    "generate_text() 함수에서 init_sentence를 인자로 받고는 있습니다. 이렇게 받은 인자를 일단 텐서로 만들고 있습니다. 디폴트로는 <start> 단어 하나만 받는군요.\n",
    "\n",
    "- while의 첫 번째 루프에서 test_tensor에 <start> 하나만 들어갔다고 합시다. 우리의 모델이 출력으로 7001개의 단어 중 A를 골랐다고 합시다.\n",
    "- while의 두 번째 루프에서 test_tensor에는 <start> A가 들어갑니다. 그래서 우리의 모델이 그다음 B를 골랐다고 합시다.\n",
    "- while의 세 번째 루프에서 test_tensor에는 <start> A B가 들어갑니다. 그래서..... (이하 후략)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> he\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-vietnam",
   "metadata": {},
   "source": [
    "제법 멋진 문장을 생성해냈군요! 위 함수의 init_sentence 를 바꿔가며 이런저런 실험을 해보세요! 단, <start>를 빼먹지는 않도록 합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-factor",
   "metadata": {},
   "source": [
    "# 4-7. 프로젝트: 멋진 작사가 만들기\n",
    "\n",
    "## Step 1. 데이터 다운로드\n",
    "\n",
    "이미 실습(1) 데이터 다듬기에서 Cloud shell에 심볼릭 링크로 \n",
    "~/aiffel/lyricist/data를 생성하셨다면, \n",
    "~/aiffel/lyricist/data/lyrics에 데이터가 있습니다.\n",
    "\n",
    "\n",
    "## Step 2. 데이터 읽어오기\n",
    "\n",
    "glob 모듈을 사용하면 파일을 읽어오는 작업을 하기가 아주 용이해요. \n",
    "glob 를 활용하여 모든 txt 파일을 읽어온 후, \n",
    "raw_corpus 리스트에 문장 단위로 저장하도록 할게요!\n",
    "\n",
    "## Step 3. 데이터 정제\n",
    "\n",
    "앞서 배운 테크닉들을 활용해 문장 생성에 적합한 모양새로 데이터를 정제하세요!\n",
    "\n",
    "preprocess_sentence() 함수를 만든 것을 기억하시죠? 이를 활용해 데이터를 정제하도록 하겠습니다.\n",
    "\n",
    "추가로 지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거합니다. 너무 긴 문장은 노래 가사 작사하기에 어울리지 않을 수도 있겠죠.\n",
    "그래서 이번에는 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외하기 를 권합니다.\n",
    "\n",
    "## Step 4. 평가 데이터셋 분리\n",
    "\n",
    "훈련 데이터와 평가 데이터를 분리하세요!\n",
    "\n",
    "tokenize() 함수로 데이터를 Tensor로 변환한 후, sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리하도록 하겠습니다. 단어장의 크기는 12,000 이상 으로 설정하세요! 총 데이터의 20% 를 평가 데이터셋으로 사용해 주세요!\n",
    "\n",
    "## Step 5. 인공지능 만들기\n",
    "\n",
    "모델의 Embedding Size와 Hidden Size를 조절하며 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계하세요! (Loss는 아래 제시된 Loss 함수를 그대로 사용!)\n",
    "\n",
    "그리고 멋진 모델이 생성한 가사 한 줄을 제출하시길 바랍니다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-hamburg",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 다운로드\n",
    "\n",
    "이미 실습(1) 데이터 다듬기에서 Cloud shell에 심볼릭 링크로 \n",
    "~/aiffel/lyricist/data를 생성하셨다면, \n",
    "~/aiffel/lyricist/data/lyrics에 데이터가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-ranch",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "covered-twelve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['[Hook]', \"I've been down so long, it look like up to me\", 'They look up to me', \"I got fake people showin' fake love to me\", 'Straight up to my face, straight up to my face', \"I've been down so long, it look like up to me\", 'They look up to me', \"I got fake people showin' fake love to me\", 'Straight up to my face, straight up to my face [Verse 1]', \"Somethin' ain't right when we talkin'\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Step 1. 데이터 다운로드\n",
    "# 이미 실습(1) 데이터 다듬기에서 Cloud shell에 심볼릭 링크로 \n",
    "# ~/aiffel/lyricist/data를 생성하셨다면, \n",
    "# ~/aiffel/lyricist/data/lyrics에 데이터가 있습니다.\n",
    "\n",
    "# Step 2. 데이터 읽어오기\n",
    "# glob 모듈을 사용하면 파일을 읽어오는 작업을 하기가 아주 용이해요. \n",
    "# glob 를 활용하여 모든 txt 파일을 읽어온 후, \n",
    "# raw_corpus 리스트에 문장 단위로 저장하도록 할게요!\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = [] # corpus의 뜻은 말뭉치\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines() # raw 에 읽어온 파일을 잘라서 넣음\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus)) # 데이터 크기 : 11176 raw_corpus의 리스트 개수 출력\n",
    "print(\"Examples:\\n\", raw_corpus[:10]) # 앞에서 9 라인만 화면에 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-behalf",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3. 데이터 정제\n",
    "\n",
    "### 3-1. preprocess_sentence() 함수제작\n",
    "\n",
    "앞서 배운 테크닉들을 활용해 문장 생성에 적합한 모양새로 데이터를 정제하세요!\n",
    "preprocess_sentence() 함수를 만든 것을 기억하시죠? \n",
    "이를 활용해 데이터를 정제하도록 하겠습니다.\n",
    "추가로 지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거합니다. \n",
    "너무 긴 문장은 노래 가사 작사하기에 어울리지 않을 수도 있겠죠. \n",
    "그래서 이번에는 문장을 토큰화 했을 때 \n",
    "토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외하기 를 권합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "popular-parameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n",
      "<start> thissentence . <end>\n",
      "<start> i eat lunch <end>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_sentence(sentence): # 입력된 문장을\n",
    "    sentence = sentence.lower().strip() # 1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2. 특수문자 양쪽에 공백을 넣고\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "    sentence = sentence.strip() # 5. 다시 양쪽 공백을 지웁니다\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "    return sentence # 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))\n",
    "print(preprocess_sentence(\"Thissentence.\"))   # 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"I eat lunch\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-chess",
   "metadata": {},
   "source": [
    "### 3-2. corpus(말뭉치) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reduced-explosion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> hook <end>',\n",
       " '<start> i ve been down so long , it look like up to me <end>',\n",
       " '<start> they look up to me <end>',\n",
       " '<start> i got fake people showin fake love to me <end>',\n",
       " '<start> straight up to my face , straight up to my face <end>',\n",
       " '<start> i ve been down so long , it look like up to me <end>',\n",
       " '<start> they look up to me <end>',\n",
       " '<start> i got fake people showin fake love to me <end>',\n",
       " '<start> somethin ain t right when we talkin <end>',\n",
       " '<start> somethin ain t right when we talkin <end>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 정제함수를 통해 만든 데이터셋에서 토큰화를 진행한 후 end단어를 없애면 소스문장,\n",
    "# 첫 단어 start를 없애면 타겟 문장이 됨\n",
    "# 이 정제함수를 활용해서 아래와 같이 정제 데이터를 구축\n",
    "# 여기에 정제된 문장을 모을겁니다\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus: # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    if len(sentence) == 0: continue\n",
    "    if len(sentence) > 50: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과를 10개만 확인해보죠\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-change",
   "metadata": {},
   "source": [
    "### 3-3. 토큰화 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recent-stream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  941    3 ...    0    0    0]\n",
      " [   2    4   94 ...   10   12    3]\n",
      " [   2   46  134 ...    0    0    0]\n",
      " ...\n",
      " [   2  198    3 ...    0    0    0]\n",
      " [   2  442    9 ...    0    0    0]\n",
      " [   2    9 1610 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f03dea67fd0>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    # maxlen=15를 설정해서 토큰의 개수가 15개를 최대로 설정, 15개 초과하는 데이터는 제외\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)\n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "loaded-ensemble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(tensor[10])) # 텐서의 길이 확인: maxlen설정으로 인해 15로 설정됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-custom",
   "metadata": {},
   "source": [
    "### 3-4. 인덱스 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "foreign-operations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-reserve",
   "metadata": {},
   "source": [
    "### 3-5. 소스 문장, 타겟 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "composite-hearts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 941   3   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[941   3   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "142443\n",
      "142443\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  # tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다. 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "tgt_input = tensor[:, 1:]    # tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])\n",
    "print(len(src_input))\n",
    "print(len(tgt_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-assumption",
   "metadata": {},
   "source": [
    "## Step 4. 평가 데이터셋 분리\n",
    "### Train, Test 데이터 분리 (Train: 80%, Test: 20%)\n",
    "\n",
    "훈련 데이터와 평가 데이터를 분리하세요!\n",
    "tokenize() 함수로 데이터를 Tensor로 변환한 후, \n",
    "\n",
    "sklearn 모듈의 train_test_split() 함수를 사용해 \n",
    "훈련 데이터와 평가 데이터를 분리하도록 하겠습니다. \n",
    "\n",
    "단어장의 크기는 12,000 이상 으로 설정하세요! \n",
    "총 데이터의 20% 를 평가 데이터셋으로 사용해 주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "devoted-eligibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (113954, 14)\n",
      "Target Train: (113954, 14)\n"
     ]
    }
   ],
   "source": [
    "# train, test 분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,\n",
    "                                                          tgt_input,\n",
    "                                                          test_size=0.2,\n",
    "                                                          shuffle=True)\n",
    "\n",
    "print(\"Source Train:\", enc_train.shape) # 소스 문장\n",
    "print(\"Target Train:\", dec_train.shape) # 타겟 문장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-deficit",
   "metadata": {},
   "source": [
    "여기까지 올바르게 진행했을 경우, 아래 실행 결과를 확인할 수 있습니다.\n",
    "out:\n",
    "\n",
    "Source Train: (124960, 14)\n",
    "Target Train: (124960, 14)\n",
    "\n",
    "만약 결과가 다르다면 천천히 과정을 다시 살펴 동일한 결과를 얻도록 하세요!\n",
    "만약 학습 데이터 개수가 124960보다 크다면 위\n",
    "Step 3.의 데이터 정제 과정을 다시 한번 검토해 보시기를 권합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "variable-quest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>\n",
      "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    "\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "dataset1 = dataset1.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset1)\n",
    "\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
    "dataset2 = dataset2.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-universe",
   "metadata": {},
   "source": [
    "## Step 5. 인공지능 만들기\n",
    "모델의 Embedding Size와 Hidden Size를 조절하며 10 Epoch 안에 val_loss 값을 \n",
    "2.2 수준으로 줄일 수 있는 모델을 설계하세요! \n",
    "(Loss는 아래 제시된 Loss 함수를 그대로 사용!)\n",
    "그리고 멋진 모델이 생성한 가사 한 줄을 제출하시길 바랍니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "productive-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "\"\"\"\n",
    "embedding_size: 워드벡터의 차원수 즉, 단어가 추상적으로 표현되는 크기.\n",
    "> 입력 텐서에는 단어 사전의 인덱스가 들어 있고, Embedding 레이어는 이 인덱스 값을 해당 인덱스의 워드 벡터로 바꿔 줍니다. \n",
    "이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현(representation)으로 사용\n",
    "embedding_size가 너무 커도 너무 작아도 문제 --> 여기서는 256로 설정\n",
    "\"\"\"\n",
    "hidden_size = 1024\n",
    "\"\"\"\n",
    "hidden_size: LSTM 레이어의 hidden state 의 차원수.\n",
    "> 얼마나 많은 일꾼을 둘 것인지? 너무 많다면 배가 산으로 가고 너무 적으면 성능이 낮다. 여기서는 1024로 적당히 설정\n",
    "\"\"\"\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "institutional-mississippi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nshape을 확인해보면 (256,14,7001)인데 \\n7001은 Dense 레이어의 출력 차원수. 7001개의 단어 중 어느 단어의 확률이 가장 높을 지 모델링 해야함.\\n\\n256은 이전 스텝에서 배치 사이즈. dataset.take(1)을 통해 1개의 배치, 즉 256개의 문장 데이터를 가져온 것.\\n\\n14는 tf.keras.layers.LSTM(hidden_size, return_sequences=True)로 호출한 LSTM 레이어에서 return_sequences=True이라고 지정한 부분에 있다.\\n즉, LSTM은 자신에게 입력된 시퀀스의 길이만큼 동일한 길이의 시퀀스를 출력한다는 의미.\\n만약 return_sequences=False였다면 LSTM 레이어는 1개의 벡터만 출력했을 것.\\n하지만 우리의 모델은 입력 데이터의 시퀀스 길이가 얼마인지 모른다는 점. 모델을 만들면서 지정하지도 않았다.\\n즉, 데이터를 입력받으면서 비로소 알게 된 것입니다. 우리 데이터셋의 max_len이 14으로 맞춰져 있었던 것\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "shape을 확인해보면 (256,14,7001)인데 \n",
    "7001은 Dense 레이어의 출력 차원수. 7001개의 단어 중 어느 단어의 확률이 가장 높을 지 모델링 해야함.\n",
    "\n",
    "256은 이전 스텝에서 배치 사이즈. dataset.take(1)을 통해 1개의 배치, 즉 256개의 문장 데이터를 가져온 것.\n",
    "\n",
    "14는 tf.keras.layers.LSTM(hidden_size, return_sequences=True)로 호출한 LSTM 레이어에서 return_sequences=True이라고 지정한 부분에 있다.\n",
    "즉, LSTM은 자신에게 입력된 시퀀스의 길이만큼 동일한 길이의 시퀀스를 출력한다는 의미.\n",
    "만약 return_sequences=False였다면 LSTM 레이어는 1개의 벡터만 출력했을 것.\n",
    "하지만 우리의 모델은 입력 데이터의 시퀀스 길이가 얼마인지 모른다는 점. 모델을 만들면서 지정하지도 않았다.\n",
    "즉, 데이터를 입력받으면서 비로소 알게 된 것입니다. 우리 데이터셋의 max_len이 14으로 맞춰져 있었던 것\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "seeing-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-1.19578035e-04  7.10515742e-05  1.01544065e-04 ... -9.23398038e-05\n",
      "    3.92192960e-05 -2.23663985e-04]\n",
      "  [-2.99180887e-04  1.71927357e-04  1.57725939e-04 ...  1.98611611e-04\n",
      "    3.35365243e-04 -2.74922961e-04]\n",
      "  [-6.71869901e-04  4.28584928e-04  5.36475331e-04 ...  1.93150059e-04\n",
      "    5.34180494e-04 -4.10876528e-04]\n",
      "  ...\n",
      "  [-1.15281169e-03  1.72764366e-03  1.55702070e-03 ... -5.50760713e-04\n",
      "    6.93818787e-04  6.14967721e-04]\n",
      "  [-1.46292092e-03  1.74762472e-03  1.39855756e-03 ... -6.10532181e-04\n",
      "    8.82885710e-04  5.36001869e-04]\n",
      "  [-1.49951049e-03  1.78394222e-03  1.15974119e-03 ... -5.09742647e-04\n",
      "    7.30809581e-04  5.48482058e-04]]\n",
      "\n",
      " [[-1.19578035e-04  7.10515742e-05  1.01544065e-04 ... -9.23398038e-05\n",
      "    3.92192960e-05 -2.23663985e-04]\n",
      "  [-1.93107389e-05 -6.38070487e-05  8.74165853e-05 ... -2.78458290e-04\n",
      "    2.61439680e-04 -5.00608643e-04]\n",
      "  [-1.08510278e-04 -1.35596798e-04  7.40868054e-05 ... -4.17035859e-04\n",
      "    4.74299421e-04 -7.64559896e-04]\n",
      "  ...\n",
      "  [ 7.97393033e-04  1.44320482e-03 -4.85516823e-04 ...  9.58156830e-04\n",
      "   -4.52738925e-04  1.13371527e-03]\n",
      "  [ 1.01469387e-03  1.48505880e-03 -6.27927948e-04 ...  1.03527401e-03\n",
      "   -6.92510745e-04  1.43698999e-03]\n",
      "  [ 1.21951185e-03  1.50716305e-03 -7.76851317e-04 ...  1.08910154e-03\n",
      "   -9.02132597e-04  1.71343156e-03]]\n",
      "\n",
      " [[-1.19578035e-04  7.10515742e-05  1.01544065e-04 ... -9.23398038e-05\n",
      "    3.92192960e-05 -2.23663985e-04]\n",
      "  [ 7.11028042e-05  1.47003637e-04 -1.95622306e-05 ... -1.67358492e-04\n",
      "   -8.60947807e-07 -2.62944086e-04]\n",
      "  [-1.20045443e-04  4.73394379e-04  1.96944340e-04 ... -2.77915155e-04\n",
      "    2.70396667e-05 -2.04297612e-04]\n",
      "  ...\n",
      "  [ 1.03230064e-03  1.21421902e-03 -7.97882618e-04 ...  9.98665346e-04\n",
      "   -7.97518180e-04  1.60847930e-03]\n",
      "  [ 1.24682055e-03  1.24910788e-03 -9.68101725e-04 ...  1.07539166e-03\n",
      "   -9.65056475e-04  1.83826790e-03]\n",
      "  [ 1.44017849e-03  1.27603998e-03 -1.13444449e-03 ...  1.12606422e-03\n",
      "   -1.11960759e-03  2.05086102e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.19578035e-04  7.10515742e-05  1.01544065e-04 ... -9.23398038e-05\n",
      "    3.92192960e-05 -2.23663985e-04]\n",
      "  [-3.16814869e-04  2.02359413e-04  1.66043275e-04 ... -2.20864647e-04\n",
      "    3.97904922e-04 -2.00583760e-04]\n",
      "  [-5.84239024e-04  2.04903379e-04  6.42418890e-05 ... -3.30429466e-04\n",
      "    5.96608676e-04 -4.46930295e-04]\n",
      "  ...\n",
      "  [ 2.84899841e-04  4.78908070e-04 -1.57388604e-05 ...  1.01256068e-03\n",
      "    5.05945703e-04  5.63393056e-04]\n",
      "  [ 5.21975220e-04  6.38113299e-04 -1.44177611e-04 ...  1.10788585e-03\n",
      "    1.80184143e-04  8.73971672e-04]\n",
      "  [ 7.72449654e-04  7.90030172e-04 -2.86084338e-04 ...  1.16950553e-03\n",
      "   -1.36976174e-04  1.17719220e-03]]\n",
      "\n",
      " [[-1.19578035e-04  7.10515742e-05  1.01544065e-04 ... -9.23398038e-05\n",
      "    3.92192960e-05 -2.23663985e-04]\n",
      "  [-1.22314159e-05  1.34042843e-04 -6.12290969e-05 ... -2.06893223e-04\n",
      "    1.41790020e-04 -9.11554816e-05]\n",
      "  [-7.81806884e-05  2.28278863e-04 -1.26360799e-04 ...  6.51498121e-05\n",
      "    4.61794640e-04 -1.49096477e-05]\n",
      "  ...\n",
      "  [ 6.98404736e-04  1.44766876e-03 -8.70908319e-04 ...  6.58841338e-04\n",
      "   -6.26558496e-04  1.59874489e-03]\n",
      "  [ 9.76466050e-04  1.44441065e-03 -9.99603071e-04 ...  7.65377888e-04\n",
      "   -8.41459841e-04  1.84127351e-03]\n",
      "  [ 1.22717023e-03  1.43856334e-03 -1.12934702e-03 ...  8.47884163e-04\n",
      "   -1.02940085e-03  2.06481596e-03]]\n",
      "\n",
      " [[-1.19578035e-04  7.10515742e-05  1.01544065e-04 ... -9.23398038e-05\n",
      "    3.92192960e-05 -2.23663985e-04]\n",
      "  [-6.15706027e-04 -1.56056514e-04 -6.99152370e-05 ... -1.51527187e-04\n",
      "    1.19641714e-04 -4.60088864e-04]\n",
      "  [-9.32961295e-04 -7.66264639e-05 -2.67333991e-04 ...  7.40736050e-06\n",
      "    1.70778367e-04 -6.54217496e-04]\n",
      "  ...\n",
      "  [-4.87827143e-04  1.15540100e-03  6.61513826e-04 ...  4.24688042e-04\n",
      "    2.11614039e-04  1.13275647e-03]\n",
      "  [-1.97895832e-04  1.19064865e-03  4.18665441e-04 ...  6.17021462e-04\n",
      "   -1.46897481e-04  1.32487237e-03]\n",
      "  [ 9.70924666e-05  1.22314284e-03  1.66749640e-04 ...  7.92096194e-04\n",
      "   -4.76132729e-04  1.53085857e-03]]], shape=(256, 14, 12001), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nshape을 확인해보면 (256,14,7001)인데 \\n7001은 Dense 레이어의 출력 차원수. 7001개의 단어 중 어느 단어의 확률이 가장 높을 지 모델링 해야함.\\n\\n256은 이전 스텝에서 배치 사이즈. dataset.take(1)을 통해 1개의 배치, 즉 256개의 문장 데이터를 가져온 것.\\n\\n14는 tf.keras.layers.LSTM(hidden_size, return_sequences=True)로 호출한 LSTM 레이어에서 return_sequences=True이라고 지정한 부분에 있다.\\n즉, LSTM은 자신에게 입력된 시퀀스의 길이만큼 동일한 길이의 시퀀스를 출력한다는 의미.\\n만약 return_sequences=False였다면 LSTM 레이어는 1개의 벡터만 출력했을 것.\\n하지만 우리의 모델은 입력 데이터의 시퀀스 길이가 얼마인지 모른다는 점. 모델을 만들면서 지정하지도 않았다.\\n즉, 데이터를 입력받으면서 비로소 알게 된 것입니다. 우리 데이터셋의 max_len이 14으로 맞춰져 있었던 것\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model이 제대로 build가 되지 않았고 model.compile()도 호출하지 않았으며 아직 model의 입력 텐서를 제대로 지정하지 않았다.\n",
    "이럴 땐 아래와 같이 model에 데이터를 아주 조금 태워 보는 것도 방법입니다. model의 input shape가 결정되면서 model.build()가 자동으로 호출\n",
    "\"\"\"\n",
    "for src_sample, tgt_sample in dataset1.take(1): break\n",
    "print(model(src_sample))\n",
    "\"\"\"\n",
    "shape을 확인해보면 (256,14,7001)인데 \n",
    "7001은 Dense 레이어의 출력 차원수. 7001개의 단어 중 어느 단어의 확률이 가장 높을 지 모델링 해야함.\n",
    "\n",
    "256은 이전 스텝에서 배치 사이즈. dataset.take(1)을 통해 1개의 배치, 즉 256개의 문장 데이터를 가져온 것.\n",
    "\n",
    "14는 tf.keras.layers.LSTM(hidden_size, return_sequences=True)로 호출한 LSTM 레이어에서 return_sequences=True이라고 지정한 부분에 있다.\n",
    "즉, LSTM은 자신에게 입력된 시퀀스의 길이만큼 동일한 길이의 시퀀스를 출력한다는 의미.\n",
    "만약 return_sequences=False였다면 LSTM 레이어는 1개의 벡터만 출력했을 것.\n",
    "하지만 우리의 모델은 입력 데이터의 시퀀스 길이가 얼마인지 모른다는 점. 모델을 만들면서 지정하지도 않았다.\n",
    "즉, 데이터를 입력받으면서 비로소 알게 된 것입니다. 우리 데이터셋의 max_len이 14으로 맞춰져 있었던 것\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "anonymous-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "german-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, \n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "indirect-disability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "445/445 [==============================] - 161s 355ms/step - loss: 3.8874 - accuracy: 0.4758 - val_loss: 2.9759 - val_accuracy: 0.5389\n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 159s 357ms/step - loss: 2.9065 - accuracy: 0.5422 - val_loss: 2.8027 - val_accuracy: 0.5518\n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 159s 356ms/step - loss: 2.7292 - accuracy: 0.5547 - val_loss: 2.6938 - val_accuracy: 0.5598\n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 159s 358ms/step - loss: 2.5966 - accuracy: 0.5636 - val_loss: 2.6147 - val_accuracy: 0.5664\n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 158s 355ms/step - loss: 2.4842 - accuracy: 0.5711 - val_loss: 2.5513 - val_accuracy: 0.5729\n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 160s 359ms/step - loss: 2.3887 - accuracy: 0.5787 - val_loss: 2.4995 - val_accuracy: 0.5787\n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 157s 353ms/step - loss: 2.2951 - accuracy: 0.5873 - val_loss: 2.4566 - val_accuracy: 0.5839\n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 158s 355ms/step - loss: 2.2195 - accuracy: 0.5945 - val_loss: 2.4188 - val_accuracy: 0.5894\n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 158s 356ms/step - loss: 2.1392 - accuracy: 0.6030 - val_loss: 2.3866 - val_accuracy: 0.5946\n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 157s 352ms/step - loss: 2.0631 - accuracy: 0.6120 - val_loss: 2.3593 - val_accuracy: 0.5998\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(dataset1,\n",
    "                          validation_data = dataset2,\n",
    "                          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "saved-principal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = model_history.history['accuracy']\n",
    "val_acc = model_history.history['val_accuracy']\n",
    "\n",
    "loss=model_history.history['loss']\n",
    "val_loss=model_history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-blake",
   "metadata": {},
   "source": [
    "### 5-2 평가하기\n",
    "- 시작 문장을 입력하면 입력된 값을 바탕으로 모델이 작문을 하는 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "documentary-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "portable-invalid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i m the one gon hold you down <end> '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bigger-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_keyword = [\"i\", \"love\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "offensive-combining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i m so much , i m not a little bit <end> \n",
      "love is , baby , baby , baby , baby , baby , baby <end> \n"
     ]
    }
   ],
   "source": [
    "for i in ai_keyword:\n",
    "    print(generate_text(model, tokenizer, init_sentence=i, max_len=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-marking",
   "metadata": {},
   "source": [
    "Q4. 모델이 생성한 가사 한 줄을 제출하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-remedy",
   "metadata": {},
   "source": [
    "평가문항|상세기준\n",
    "---|---\n",
    "1. 가사 텍스트 생성 모델이 정상적으로 동작하는가?|텍스트 제너레이션 결과가 그럴듯한 문장으로 생성되는가?\n",
    "2. 데이터의 전처리와 데이터셋 구성 과정이 체계적으로 진행되었는가?|특수문자 제거, 토크나이저 생성, 패딩처리 등의 과정이 빠짐없이 진행되었는가?\n",
    "3. 텍스트 생성모델이 안정적으로 학습되었는가?|텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-poultry",
   "metadata": {},
   "source": [
    "1) 기존에 사용했던 CNN + Dense와 어떤차이가있을까\n",
    "가위바위보 했던 \n",
    "LSTM\n",
    "어텐션\n",
    "\n",
    "\n",
    "2) pad를 왜 사용해야할까\n",
    "\n",
    "토크나이저\n",
    "\n",
    "패딩\n",
    "\n",
    "쀍쀍 데이터\n",
    "\n",
    "3)4-4처럼 학습하면 결과물로 어떤 결과가 나온건지에 대해\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
